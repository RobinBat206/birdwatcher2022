{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a838f241",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "<a id=\"top\"></a>\n",
    "# Bird Watcher Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa46812",
   "metadata": {},
   "source": [
    "## Resources Provided\n",
    "- Images provided for testing [Test_Images](https://github.com/ahuynh30/Summer_course_material).\n",
    "- Intel DevCloud [Open Model Zoo](https://github.com/openvinotoolkit/open_model_zoo/tree/master/models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c254efc5",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe342a3",
   "metadata": {},
   "source": [
    "### Import your Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e461dba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import copy\n",
    "from openvino.inference_engine import IECore\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77187bd7",
   "metadata": {},
   "source": [
    "# Setting up the inference engine for local testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8332376e",
   "metadata": {},
   "source": [
    "This is to show you how we will be accessing our files without having to look up the names of our files. \n",
    "- What you see below is the function listdir which is part of the os library, this allows us to select a folder location and it will list us all the files inside it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6467eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of directory \n",
    "os.listdir(\"Summer_course_material-main/photos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff8e00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# because we dont want hidden files \n",
    "# this sorts all the hidden files out. \n",
    "def listdir_nohidden(path):\n",
    "    \"\"\"\n",
    "    this filters out any hidden files that start with a period.\n",
    "    this also only lists the photos in a given folder/directory\n",
    "    inputs:\n",
    "        path: this is the directory location that you want a list of whatever files are in it\n",
    "    output: \n",
    "        lists: this is my list of files in the folder location without any hidden files\n",
    "    \"\"\"\n",
    "    lists = []\n",
    "    unfiltered = os.listdir(path)\n",
    "    for pathings in unfiltered:\n",
    "        if pathings.endswith('.jpg'): #jpeg images\n",
    "            lists.append(pathings)\n",
    "        elif pathings.endswith('.png'): # png images\n",
    "            lists.append(pathings)\n",
    "        elif pathings.endswith('.webp'): # website images\n",
    "            lists.append(pathings)\n",
    "        elif pathings.endswith('.jfif'): #compressed jpeg images\n",
    "            lists.append(pathings)\n",
    "        elif pathings.endswith('.jpeg'): #jpeg images\n",
    "            lists.append(pathings)\n",
    "    lists.sort() #  sorts it in alphabetical order\n",
    "    return lists\n",
    "test = listdir_nohidden(\"Summer_course_material-main/photos\")        \n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5560d9f2",
   "metadata": {},
   "source": [
    "## Configuring the inference engine settings and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27b3f01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model IR files\n",
    "model_xml = \"models/public/mobilenet-ssd/FP16/mobilenet-ssd.xml\"\n",
    "model_bin = \"models/public/mobilenet-ssd/FP16/mobilenet-ssd.bin\"\n",
    "\n",
    "# single input image file\n",
    "input_path = \"\"\n",
    "# This is only for single input\n",
    "\n",
    "# CPU extension library to use\n",
    "cpu_extension_path = os.path.expanduser(\"~\")+\"/inference_engine_samples/intel64/Release/lib/libcpu_extension.so\"\n",
    "\n",
    "# device to use\n",
    "device = \"CPU\"\n",
    "\n",
    "# output labels \n",
    "labels_path = \"labels.txt\"\n",
    "\n",
    "# minimum probability threshold to detect an object\n",
    "prob_threshold = 0.5\n",
    "\n",
    "print(\"Configuration parameters settings:\"\n",
    "     \"\\n\\tmodel_xml=\", model_xml,\n",
    "      \"\\n\\tmodel_bin=\", model_bin,\n",
    "      \"\\n\\tinput_path=\", input_path,\n",
    "      \"\\n\\tdevice=\", device, \n",
    "      \"\\n\\tlabels_path=\", labels_path, \n",
    "      \"\\n\\tprob_threshold=\", prob_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9b9d52",
   "metadata": {},
   "source": [
    "#### Creating the Inference Engine Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fd5697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Inference Engine instance\n",
    "ie = IECore()\n",
    "print(\"An Inference Engine object has been created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c10a26c",
   "metadata": {},
   "source": [
    "#### Create Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f5c830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load network from IR files\n",
    "net = ie.read_network(model=model_xml, weights=model_bin)\n",
    "print(\"Loaded model IR files [\",model_xml,\"] and [\", model_bin, \"]\\n\")\n",
    "\n",
    "# check to make sure that the plugin has support for all layers in the loaded model\n",
    "supported_layers = ie.query_network(net,device)\n",
    "\n",
    "# check to make sue that the model's input and output are what is expected\n",
    "assert len(net.input_info.keys()) == 1, \\\n",
    "    \"ERROR: This sample supports only single input topologies\"\n",
    "assert len(net.outputs) == 1, \\\n",
    "    \"ERROR: This sample supports only single output topologies\"\n",
    "print(\"SUCCESS: Model IR files have been loaded and verified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a779c7d9",
   "metadata": {},
   "source": [
    "#### load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399ce5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model into the Inference Engine for our device\n",
    "exec_net = ie.load_network(network=net, num_requests=2, device_name=device)\n",
    "\n",
    "# store name of input and output blobs\n",
    "input_blob = next(iter(net.input_info))\n",
    "\n",
    "output_blob = next(iter(net.outputs))\n",
    "\n",
    "\n",
    "# read the input's dimensions: n=batch size, c=number of channels, h=height, w=width\n",
    "n, c, h, w = net.input_info[input_blob].input_data.shape\n",
    "print(\"Loaded model into Inference Engine for device:\", device, \n",
    "      \"\\nModel input dimensions: n=\",n,\", c=\",c,\", h=\",h,\", w=\",w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c03aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_blob\n",
    "#{'data',[batches[[r][g][b],[h],[w]]}\n",
    "#output_blob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e187a238",
   "metadata": {},
   "source": [
    "#### Load labels\n",
    "\n",
    "this is loading the label and creating it if it isnt there\n",
    "- to create the a label you must first go to the github to the label list\n",
    " [mobilenet-ssd](https://github.com/openvinotoolkit/open_model_zoo/tree/master/models/public/mobilenet-ssd).\n",
    " \n",
    " If you scroll down, you can see that it tells us that the label list for the mobilenet-ssd is located in the \n",
    " \n",
    " <omz_dir>/data/dataset_classes/voc_20cl_bkgr.txt\n",
    "- this means that if we go to [voc_20cl_bkgr.txt](https://github.com/openvinotoolkit/open_model_zoo/blob/master/data/dataset_classes/voc_20cl_bkgr.txt). We can see the list and then copy paste it below to create our txt file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b14e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile labels.txt\n",
    "background\n",
    "aeroplane\n",
    "bicycle\n",
    "bird\n",
    "boat\n",
    "bottle\n",
    "bus\n",
    "car\n",
    "cat\n",
    "chair\n",
    "cow\n",
    "diningtable\n",
    "dog\n",
    "horse\n",
    "motorbike\n",
    "person\n",
    "pottedplant\n",
    "sheep\n",
    "sofa\n",
    "train\n",
    "tvmonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227f65b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels_map = None\n",
    "# if labels points to a label mapping file, then load the file into labels_map\n",
    "print(labels_path)\n",
    "if os.path.isfile(labels_path):\n",
    "    with open(labels_path, 'r') as f:\n",
    "        labels_map = [x.split(sep=' ', maxsplit=1)[-1].strip() for x in f]\n",
    "    print(\"Loaded label mapping file [\",labels_path,\"]\")\n",
    "else:\n",
    "    print(\"No label mapping file has been loaded, only numbers will be used\",\n",
    "          \" for detected object labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbff0fb4",
   "metadata": {},
   "source": [
    "#### Load the Input image/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1d099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to load an input image\n",
    "def loadInputImage(input_path, verbose = True):\n",
    "    # use OpenCV to load the input image\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    width = cap.get(3)\n",
    "    height = cap.get(4)\n",
    "    input_w.append(width)\n",
    "    input_h.append(height)\n",
    "    \n",
    "    # store input width and height\n",
    "    if verbose: \n",
    "        print(\"Loaded input image [\",input_path,\"], resolution=\", width, \"w x \",height,\"h\")\n",
    "\n",
    "    # load the input image\n",
    "    ret, image = cap.read()\n",
    "    del cap\n",
    "    \n",
    "    return image\n",
    "\n",
    "# define function for resizing input image\n",
    "def resizeInputImage(image, verbose = True):\n",
    "    # resize image dimensions form image to model's input w x h\n",
    "    in_frame = cv2.resize(image, (w,h))\n",
    "    # Change data layout from HWC to CHW\n",
    "    # HWC -> 0,1,2 \n",
    "    in_frame = in_frame.transpose((2, 0, 1)) \n",
    "    # reshape to input dimensions\n",
    "    in_frame = in_frame.reshape((n, c, h, w))\n",
    "    if verbose: \n",
    "        print(\"Resized input image from {} to {}\".format(image.shape[:-1], (h, w)))\n",
    "    return in_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560fd0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR MULTI IMAGE INFERENCES\n",
    "# define function to load input images into input batch\n",
    "def batchLoadInputImages(batch_paths,Text):\n",
    "    global batch_size\n",
    "    global batch_images\n",
    "    global orig_image_paths\n",
    "    global orig_images\n",
    "    batch_size = len(batch_paths)\n",
    "    #print(batch_size)\n",
    "\n",
    "    # create input batch (array) of input images \n",
    "    batch_images = np.ndarray(shape=(batch_size, c, h, w))\n",
    "\n",
    "    # create array to hold original images and paths for displaying later\n",
    "    orig_images = []\n",
    "    orig_image_paths = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        # load image\n",
    "        image = loadInputImage(batch_paths[i],Text)\n",
    "        # save original image and path\n",
    "        orig_images.append(image)\n",
    "        orig_image_paths.append(batch_paths[i])\n",
    "        # prepare input\n",
    "        in_frame = resizeInputImage(image,Text)\n",
    "        # add input to batch\n",
    "        batch_images[i] = in_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d311eb",
   "metadata": {},
   "source": [
    "##### This is for when you input multiple images"
   ]
  },
  {
   "cell_type": "raw",
   "id": "11b10c7b",
   "metadata": {},
   "source": [
    "image = cv2.imread(\"\")\n",
    "test = cv2.resize(image, (227, 227))\n",
    "cap = cv2.VideoCapture(\"\") \n",
    "test2 = \"\"\n",
    "# store input width and height\n",
    "input_w.append(cap.get(3))\n",
    "input_h.append(cap.get(4))\n",
    "print(\"Loaded input image [\",test2,\"], resolution=\", cap.get(3), \"w x \",cap.get(4),\"h\")\n",
    "\n",
    "# load the input image\n",
    "ret, image = cap.read()\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d01e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadImages(directory,Text:bool):\n",
    "    #img_files = listdir_nohidden(\"\")\n",
    "    global img_files\n",
    "    img_files = listdir_nohidden(directory)\n",
    "    # need this to initialize the batch_paths and also reset those variables \n",
    "    batch_paths = []\n",
    "    for path in img_files:\n",
    "        temp = directory + \"/\" + path\n",
    "        # temp = Summer_course_material-main/photos/Pitbull.jpg\n",
    "        batch_paths.append(temp)\n",
    "    # globals to store input width and height\n",
    "    global input_w, input_h\n",
    "    # need this to initialize the input w and input h and also reset those variables \n",
    "    input_w = []\n",
    "    input_h = []\n",
    "    batchLoadInputImages(batch_paths,Text)\n",
    "    print(\"Loaded\", batch_size, \"images.\")\n",
    "    global img_names\n",
    "    img_names = []\n",
    "    for path in img_files:\n",
    "        temp = path.split(\".\")\n",
    "        #display(temp) #used to see what temp was storing\n",
    "        img_names.append(temp[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be934afe",
   "metadata": {},
   "source": [
    "## loading image block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785d0a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"Summer_course_material-main/photos\"\n",
    "LoadImages(directory,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dbb0b6",
   "metadata": {},
   "source": [
    "#### Run Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6664946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunInference():\n",
    "    # save start time\n",
    "    inf_start = time.time()\n",
    "    global All_detections\n",
    "    #comment out the res that you are not using between the single and multi\n",
    "    # run single inference\n",
    "    #res = exec_net.infer(inputs={input_blob: in_frame})   \n",
    "\n",
    "    # run multiple image batch inference\n",
    "    All_detections = []\n",
    "    for i in batch_images:\n",
    "        temp = exec_net.infer(inputs={input_blob: i}) \n",
    "        All_detections.append(temp)   \n",
    "\n",
    "    # calculate time from start until now\n",
    "    inf_time = time.time() - inf_start\n",
    "    print(\"Inference complete, run time: {:.3f} ms\".format(inf_time * 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd4fd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RunInference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bcccf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_blob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c908f9",
   "metadata": {},
   "source": [
    "## Processing the Results and Storing the Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45bef58",
   "metadata": {},
   "source": [
    "### Multiple inputs definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e76bcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to process inference results\n",
    "def processResults(detection,image_index,Raw_location,Inference_location):\n",
    "    # get output results\n",
    "    bird_count = 0\n",
    "    res = detection[output_blob]\n",
    "    image = orig_images[image_index]\n",
    "    # reasonn why we need to make a copy is because we want to show original image as well \n",
    "    image_og = copy.copy(orig_images[image_index])\n",
    "    width = input_w[image_index]\n",
    "    height = input_h[image_index]\n",
    "    # loop through all possible results\n",
    "    # goes through a 1,1,100,7\n",
    "    # obj runs 100 times and sees confidence level\n",
    "    # [0][0] is elimateing the 1st and 2nd matrix dimensions 1,1 \n",
    "    # leaving us with 100 loops of 7 values per loop\n",
    "    # _, 1000\n",
    "    #bird_count = 0\n",
    "    #res = [[7]  [7]  [7]..... ]\n",
    "    # res = [[1] [2] [3]  ....\n",
    "    # [image_id, label, conf, x_min, y_min, x_max, y_max],\n",
    "    for obj in res[0][0]:\n",
    "        # If probability is more than specified threshold, draw and label box \n",
    "        if obj[2] > prob_threshold:\n",
    "            # get coordinates of box containing detected object\n",
    "            # height is for y axis\n",
    "            # width is for x axis\n",
    "            xmin = int(width * obj[3])\n",
    "            ymin = int(height* obj[4])\n",
    "            xmax = int(width * obj[5])\n",
    "            ymax = int(height* obj[6])\n",
    "            \n",
    "            # get type of object detected\n",
    "            class_id = int(obj[1])\n",
    "            if class_id == 3: # this is checking for bird images\n",
    "                #store raw image file of bird first;\n",
    "                bird_count +=1\n",
    "                new_path=Raw_location+\"/\"+img_names[image_index]+\"_\"+str(bird_count)+\".jpg\"\n",
    "                # ex: new_path = results/raw_bird_image/Pitbull_1.jpg\n",
    "                cv2.imwrite(new_path, image_og)\n",
    "                \n",
    "                \n",
    "            # Draw box and label for detected object\n",
    "            color = (min(class_id * 12.5, 255), 255, 255)\n",
    "            cv2.rectangle(image, (xmin, ymin), (xmax, ymax), color, int(width*0.01))\n",
    "            det_label = labels_map[class_id] if labels_map else str(class_id)\n",
    "            cv2.putText(image, det_label + ' ' + str(round(obj[2] * 100, 1)) + ' %', (xmin, ymin - 7),\n",
    "                        cv2.FONT_HERSHEY_COMPLEX, int(width*0.003), color, 2) \n",
    "            if class_id == 3: # this is checking for bird images\n",
    "                #store inference image file of bird ;\n",
    "                new_path=Inference_location+\"/\"+img_names[image_index]+\"_\"+str(bird_count)+\".jpg\"\n",
    "                # ex: new_path = results/inference_bird_image/Pitbull_1.jpg\n",
    "                cv2.imwrite(new_path, image)\n",
    "                \n",
    "    return bird_count\n",
    "\n",
    "def batchProcessResults(All_Detection,Raw_location,Inference_location):\n",
    "    # get output results\n",
    "    #res = result[output_blob]\n",
    "    image_index = 0\n",
    "    total_birds = 0\n",
    "    for detection in All_Detection:\n",
    "\n",
    "        bird_count = processResults(detection,image_index, Raw_location,Inference_location)\n",
    "        image_index += 1\n",
    "        total_birds += bird_count\n",
    "    return total_birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82725e61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def RunImageProcessing(All_detections, Raw_location,Inference_location):\n",
    "    # save start time\n",
    "    global bird_count\n",
    "    inf_start = time.time()\n",
    "    bird_count = batchProcessResults(All_detections, Raw_location,Inference_location)\n",
    "    # calculate time from start until now\n",
    "    inf_time = time.time() - inf_start\n",
    "    mins = round(inf_time/60)\n",
    "    sec = inf_time%60\n",
    "    print(\"Processing Results runtime, run time: {} minutes\" .format(mins), \"and {:.3f} seconds \" .format(sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c547ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Raw_location       = \"results/raw_bird_image\"\n",
    "Inference_location = \"results/inference_bird_image\"\n",
    "RunImageProcessing(All_detections, Raw_location,Inference_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5d501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60129278",
   "metadata": {},
   "source": [
    "### Displaying all the bird images found. \n",
    "- one with the bird image only\n",
    "- one with the inference displayed on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee30189",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def DisplayImages(Raw_location,Inference_location):\n",
    "    # test retrieve the image locally \n",
    "    #only ran after running all the bird images \n",
    "    result_path = listdir_nohidden(Raw_location)\n",
    "    result_path.sort() #sorts it by alphabetical\n",
    "    if bird_count == 0:\n",
    "        display(\"No birds Found\")\n",
    "    else:\n",
    "        print(bird_count, \"birds found\")\n",
    "        for i in range(0,bird_count):\n",
    "            raw_img_path   = Raw_location +\"/\"+ result_path[i]\n",
    "            infer_img_path = Inference_location +\"/\"+ result_path[i]\n",
    "            raw_img   = cv2.imread(raw_img_path)    # this is BGR\n",
    "            infer_img = cv2.imread(infer_img_path)  # this is BGR\n",
    "            raw_img   = cv2.cvtColor(raw_img,cv2.COLOR_BGR2RGB)\n",
    "            infer_img = cv2.cvtColor(infer_img,cv2.COLOR_BGR2RGB)\n",
    "            plt.figure()\n",
    "            plt.title(raw_img_path)\n",
    "            plt.imshow(raw_img)\n",
    "            plt.axis(\"off\")\n",
    "            plt.figure()\n",
    "            plt.title(infer_img_path)\n",
    "            plt.imshow(infer_img)\n",
    "            plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1000e8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Raw_location       = \"results/raw_bird_image\"\n",
    "Inference_location = \"results/inference_bird_image\"\n",
    "DisplayImages(Raw_location,Inference_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42db527d",
   "metadata": {},
   "source": [
    "## Regular inference blocks to rerun it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8f95b4",
   "metadata": {},
   "source": [
    "### loading image block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5002380",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"Summer_course_material-main/photos\"\n",
    "LoadImages(directory,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22830b19",
   "metadata": {},
   "source": [
    "### Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d113ba54",
   "metadata": {},
   "outputs": [],
   "source": [
    "RunInference()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c99961",
   "metadata": {},
   "source": [
    "### Process Images and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b75cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Raw_location       = \"results/raw_bird_image\"\n",
    "Inference_location = \"results/inference_bird_image\"\n",
    "RunImageProcessing(All_detections, Raw_location,Inference_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff7033f",
   "metadata": {},
   "source": [
    "### Display Result images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5966f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "Raw_location       = \"results/raw_bird_image\"\n",
    "Inference_location = \"results/inference_bird_image\"\n",
    "DisplayImages(Raw_location,Inference_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c54d2a7",
   "metadata": {},
   "source": [
    "# This is going to be greyscale image testing. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1165dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert an image to grayscale\n",
    "    \n",
    "    Inputs:\n",
    "        image: np.ndarray that represents an image\n",
    "    Outputs:\n",
    "        changed_image: np.ndarray that represents the changed image to grayscale\n",
    "    \"\"\"\n",
    "    grey_image = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "    changed_image = cv2.cvtColor(grey_image, cv2.COLOR_GRAY2RGB)\n",
    "    return changed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f72ab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir Summer_course_material-main/photos_grayscale\n",
    "!mkdir results/Gray_raw_bird_image\n",
    "!mkdir results/Gray_inference_bird_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b0d3dd",
   "metadata": {},
   "source": [
    "### This is where we create our grayscale images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04ac1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_files = listdir_nohidden(\"Summer_course_material-main/photos\")\n",
    "\n",
    "for path in img_files:\n",
    "    #this is where our current image is found \n",
    "    temp  = \"Summer_course_material-main/photos/\"+ path\n",
    "    image = cv2.imread(temp)\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    # converting from RGB to greyscale\n",
    "    grayscaled = grayscale(image)\n",
    "    grayscaled = cv2.cvtColor(grayscaled,cv2.COLOR_RGB2BGR)\n",
    "    # this will be where our new photo is stored\n",
    "    new_path = \"Summer_course_material-main/photos_grayscale/Gray_\" + path\n",
    "    # Summer_course_material-main/photos_grayscale/Gray_Pitbull.jpg\n",
    "    cv2.imwrite(new_path,grayscaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f4f953",
   "metadata": {},
   "source": [
    "### loading image block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb80792",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"Summer_course_material-main/photos_grayscale\"\n",
    "LoadImages(directory,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a728814",
   "metadata": {},
   "source": [
    "### Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c1196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RunInference()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aaae44",
   "metadata": {},
   "source": [
    "### Process Images and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1886f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "Raw_location       = \"results/Gray_raw_bird_image\"\n",
    "Inference_location = \"results/Gray_inference_bird_image\"\n",
    "RunImageProcessing(All_detections, Raw_location,Inference_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13009ee3",
   "metadata": {},
   "source": [
    "### Display Result images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a8c603",
   "metadata": {},
   "outputs": [],
   "source": [
    "Raw_location       = \"results/Gray_raw_bird_image\"\n",
    "Inference_location = \"results/Gray_inference_bird_image\"\n",
    "DisplayImages(Raw_location,Inference_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a837cd4a",
   "metadata": {},
   "source": [
    "## This is where we will rotate the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdb52a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotateImage(image: np.ndarray) -> np.ndarray:\n",
    "    changed_image = np.rot90(image)\n",
    "    return changed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91d0d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir Summer_course_material-main/photos_Rotated\n",
    "!mkdir results/Rotated_raw_bird_image\n",
    "!mkdir results/Rotated_inference_bird_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2e5003",
   "metadata": {},
   "source": [
    "### This is where we create our Rotated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0b60c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_files = listdir_nohidden(\"Summer_course_material-main/photos\")\n",
    "\n",
    "for path in img_files:\n",
    "    #this is where our current image is found \n",
    "    temp  = \"Summer_course_material-main/photos/\"+ path\n",
    "    image = cv2.imread(temp)\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    # converting from RGB to greyscale\n",
    "    rotated = rotateImage(image)\n",
    "    rotate = cv2.cvtColor(rotated,cv2.COLOR_RGB2BGR)\n",
    "    # this will be where our new photo is stored\n",
    "    new_path = \"Summer_course_material-main/photos_rotated/Rotated_\" + path\n",
    "    # Summer_course_material-main/photos_grayscale/Gray_Pitbull.jpg\n",
    "    cv2.imwrite(new_path,rotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262c0140",
   "metadata": {},
   "source": [
    "### loading image block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397d1dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"Summer_course_material-main/photos_Rotated\"\n",
    "LoadImages(directory,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8b90e2",
   "metadata": {},
   "source": [
    "### Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f6d2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "RunInference()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51c894d",
   "metadata": {},
   "source": [
    "### Process Images and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ca03ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Raw_location       = \"results/Rotated_raw_bird_image\"\n",
    "Inference_location = \"results/Rotated_inference_bird_image\"\n",
    "RunImageProcessing(All_detections, Raw_location,Inference_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cbd4f0",
   "metadata": {},
   "source": [
    "### Display Result images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dbdca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Raw_location       = \"results/Rotated_raw_bird_image\"\n",
    "Inference_location = \"results/Rotated_inference_bird_image\"\n",
    "DisplayImages(Raw_location,Inference_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47c5dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = 'Rotated_'\n",
    "birds_total = {header+'birdhouse': 1, header+'birdling': 1, header+'birds_at_river': 16,header+ 'birds_in_cactus': 2, header+'black': 1, 'branch_bird': 1, header+'cactus_bird': 1, header+'crane': 1, header+'desert_owl': 1, header+'eagle': 1, header+'needle_bird': 1,header+ 'nesting_bird': 1,header+ 'owl': 1, header+'parrot': 1, header+'penguin': 7,header+ 'pigeons': 10,header+ 'pink_blue_bird': 1, header+'red_beak_bird': 1,header+ 'roadrunner': 1,header+ 'seagull': 1, header+'secretary_bird': 1, header+'single_pigeon': 1,header+ 'tall_bird': 1, header+'three_birds': 3,header+ 'toucan': 1,header+ 'turkey': 1, header+'vultures': 3, header+'white_bird': 1, header+'yellow_bird': 1}\n",
    "inferences = [x.replace(\"_\" + x.split(\"_\")[len(x.split(\"_\")) - 1], \"\") for x in listdir_nohidden(\"results/Rotated_inference_bird_image\")]\n",
    "\n",
    "print(\"POSSIBLE TRUE POSITIVES\") \n",
    "false_negative = []\n",
    "partial_true_positive = []\n",
    "\n",
    "for bird in birds_total:\n",
    "    count = inferences.count(bird)\n",
    "    total = birds_total[bird]\n",
    "    padding = \".......................\"[0:-len(bird)]\n",
    "    string = bird + padding + str(count) + \"/\" + str(total)\n",
    "    if count == 0:\n",
    "        false_negative.append(string)\n",
    "    elif count != total:\n",
    "        partial_true_positive.append(string)\n",
    "    else:\n",
    "        print(string)\n",
    "\n",
    "print(\"\\nPOSSIBLE PARTIAL TRUE POSITIVES\")\n",
    "for inf in partial_true_positive:\n",
    "    print(inf)\n",
    "\n",
    "print(\"\\nFALSE NEGATIVES\")    \n",
    "for inf in false_negative:\n",
    "    print(inf)\n",
    "    \n",
    "print(\"\\nFALSE POSITIVES\")\n",
    "for inf in inferences:\n",
    "    if inf not in birds_total:\n",
    "        print(inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5192b0",
   "metadata": {},
   "source": [
    "## This is where we will add black borders to the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea945e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Square_border(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    square the image by adding black borders\n",
    "    Inputs:\n",
    "        image: np.ndarray that represents an image\n",
    "    Outputs:\n",
    "        changed_image: np.ndarray that represents the squared image\n",
    "    \"\"\"\n",
    "    height,width,channels = image.shape\n",
    "    if height > width: #finding which side is longer\n",
    "        Square_size = height\n",
    "        smallerSide = width\n",
    "        orientation = 'LeftRight'\n",
    "    else:\n",
    "        Square_size = width\n",
    "        smallerSide = height\n",
    "        orientation = 'UpDown'\n",
    "    #create new square dimensions\n",
    "    dimensions = (Square_size,Square_size,channels)\n",
    "    #creaate the black square using zeros\n",
    "    Square_img =  np.zeros(dimensions, dtype=np.uint8)\n",
    "    #create the border size to position the image correctly\n",
    "    BorderSize = int((Square_size - smallerSide) / 2)\n",
    "    if orientation == 'UpDown':\n",
    "        Square_img[BorderSize:BorderSize+smallerSide,:] = image\n",
    "    elif orientation == 'LeftRight':\n",
    "        Square_img[:, BorderSize:BorderSize+smallerSide] = image\n",
    "    changed_image = Square_img\n",
    "    return changed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c063e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir Summer_course_material-main/photos_border\n",
    "!mkdir results/Border_raw_bird_image\n",
    "!mkdir results/Border_inference_bird_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702db43d",
   "metadata": {},
   "source": [
    "### This is where we square our images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb27e93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_files = listdir_nohidden(\"Summer_course_material-main/photos\")\n",
    "for path in img_files:\n",
    "    #this is where our current image is found \n",
    "    temp  = \"Summer_course_material-main/photos/\"+ path\n",
    "    image = cv2.imread(temp)\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    # converting from RGB to greyscale\n",
    "    Square = Square_border(image)\n",
    "    Square = cv2.cvtColor(Square,cv2.COLOR_RGB2BGR)\n",
    "    # this will be where our new photo is stored\n",
    "    new_path = \"Summer_course_material-main/photos_border/Border_\" + path\n",
    "    # Summer_course_material-main/photos_grayscale/Gray_Pitbull.jpg\n",
    "    cv2.imwrite(new_path,Square)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409a3090",
   "metadata": {},
   "source": [
    "### loading image block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab9f137",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"Summer_course_material-main/photos_border\"\n",
    "LoadImages(directory,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acbc4cf",
   "metadata": {},
   "source": [
    "### Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da53b72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RunInference()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c14275c",
   "metadata": {},
   "source": [
    "### Process Images and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f54aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Raw_location       = \"results/Border_raw_bird_image\"\n",
    "Inference_location = \"results/Border_inference_bird_image\"\n",
    "RunImageProcessing(All_detections, Raw_location,Inference_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59636a16",
   "metadata": {},
   "source": [
    "### Display Result images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64799071",
   "metadata": {},
   "outputs": [],
   "source": [
    "Raw_location       = \"results/Border_raw_bird_image\"\n",
    "Inference_location = \"results/Border_inference_bird_image\"\n",
    "DisplayImages(Raw_location,Inference_location)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "383px",
    "width": "384px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "339.062px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
